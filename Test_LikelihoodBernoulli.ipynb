{
 "metadata": {
  "name": "",
  "signature": "sha256:3747850c7b4d511a876fdf444cefaf62d3066845ef151bbe857121b192af08f5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from scipy import linalg\n",
      "import hips.distributions.polya_gamma as pg\n",
      "%matplotlib inline\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Generate test data\n",
      "K = 150\n",
      "dN = np.random.rand(K) > .9\n",
      "sigma2e = .05"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Likelihood of a state-space model with Bernoulli observations\n",
      "\n",
      "The log-likelihood is\n",
      "\\begin{align*}\n",
      "\\log p(N_{0,K}, x; \\theta) &= \\log p(N_{0,K}|x) + \\log p(x; \\theta) \\\\\n",
      "&= \\sum\\limits_{k=1}^{K} \\log p(\\Delta N_{k}|x_k) + \\sum\\limits_{k=1}^{K} \\log p(x_k|x_{k-1}; \\sigma_{\\epsilon}^2) \\\\\n",
      "&= \\sum\\limits_{k=1}^{K} \\left[\\Delta N_{k} \\log\\left(\\frac{e^{x_k}}{1+e^{x_k}}\\right) + (1-\\Delta N_{k}) \\log\\left(\\frac{1}{1+e^{x_k}}\\right) \\right] + \\pi(x; \\theta) \\\\\n",
      "&= \\sum\\limits_{k=1}^{K} \\left[ \\Delta N_{k} \\, x_k - \\log(1+e^{x_k}) \\right] + \\pi(x; \\theta)\n",
      "\\end{align*}\n",
      "where\n",
      "$$\n",
      "\\pi(x; \\theta) = - \\frac{K}{2} \\log(2\\pi\\sigma_{\\epsilon}^2) - \\frac{1}{2\\sigma_{\\epsilon}^2} \\sum\\limits_{k=1}^{K} (x_k - x_{k-1})^2\n",
      "$$"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Marginal likelihood using Polya-Gamma $PG(1,0)$ latent variables\n",
      "\n",
      "Using the Polya-Gamma latent variables $w_k \\sim PG(1,0)$, we can rewrite $p(\\Delta N_{k}|x_k)$ as (see http://dx.doi.org/10.1080/01621459.2013.829001)\n",
      "\\begin{align}\n",
      "p(\\Delta N_{k}|x_k) &= \\frac{e^{x_k\\,\\Delta N_k}}{1+e^{x_k}} = \\frac12 e^{w_k \\, y_k \\, x_k} \\int\\limits_{0}^{\\infty} e^{-w_k \\, x_k^2 / 2} \\, p(w_k) \\, dw_k \\\\\n",
      "&= \\int\\limits_{0}^{\\infty} \\frac{e^{w_k \\, y_k^2 / 2}}{\\sqrt{2 \\pi^{-1} w_k}} \\left[ \\frac{1}{\\sqrt{2\\pi w_k^{-1}}} e^{-\\frac{1}{2 \\, w_k^{-1}} \\left(y_k - x_k\\right)^2} \\right] p(w_k) \\, dw_k\n",
      "\\end{align}\n",
      "where $y_k = \\frac{\\Delta N_k - 1/2}{w_k}$.\n",
      "\n",
      "So, the data likelihood can be written as\n",
      "\\begin{align}\n",
      "p(N_{0,K}, x; \\theta) &= \\int\\limits_{w \\in \\mathbb{R}_{+}^K} c(w,y) \\, p(y,x; w^{-1}, \\sigma_{\\epsilon}^2) \\,  p(w) \\, dw\n",
      "\\end{align}\n",
      "where\n",
      "\\begin{align}\n",
      "c(w,y) &= \\frac{e^{\\sum_{k=1}^K w_k \\, y_k^2 / 2}}{\\prod_{k=1}^K\\sqrt{2 \\pi^{-1} w_k}}, \\\\\n",
      "p(y,x; w^{-1}, \\sigma_{\\epsilon}^2) &= \\prod_{k=1}^K \\left[\n",
      "\\frac{1}{\\sqrt{2\\pi w_k^{-1}}} e^{-\\frac{1}{2 \\, w_k^{-1}} \\left(y_k - x_k\\right)^2} \\,\n",
      "\\frac{1}{\\sqrt{2\\pi \\sigma_{\\epsilon}^2}} e^{-\\frac{1}{2 \\, \\sigma_{\\epsilon}^2} \\left(x_k - x_{k-1}\\right)^2}\n",
      "\\right]\n",
      "\\end{align}\n",
      "The term $p(y,x; w^{-1}, \\sigma_{\\epsilon}^2)$ is the data likelihood of a Gaussian state-space model with observations $y_k$, measurement noise with variance $w_k^{-1}$ and process noise $\\sigma_{\\epsilon}^2$.\n",
      "\n",
      "We can now compute the marginal likelihood as\n",
      "\\begin{align}\n",
      "p(N_{0,K}; \\theta) &= \\int\\limits_{x \\in \\mathbb{R}^K} \\; \\int\\limits_{w \\in \\mathbb{R}_{+}^K} c(w,y) \\, p(y,x; w^{-1}, \\sigma_{\\epsilon}^2) \\, p(w) \\, dw \\, dx \\\\\n",
      "&= \\int\\limits_{w \\in \\mathbb{R}_{+}^K} c(w,y) \\left[ \\int\\limits_{x \\in \\mathbb{R}^K} p(y,x; w^{-1}, \\sigma_{\\epsilon}^2) \\, dx \\right] p(w) \\, dw \\\\\n",
      "&= \\int\\limits_{w \\in \\mathbb{R}_{+}^K} c(w,y) \\, p(y; w^{-1}, \\sigma_{\\epsilon}^2) \\, dw\n",
      "\\end{align}\n",
      "where\n",
      "\\begin{align}\n",
      "J &= \\nabla_x^2 [-\\log p(y,x; w^{-1}, \\sigma_{\\epsilon}^2)]\\\\\n",
      "x_{\\mathrm{MAP}} &= 0_K - J^{-1} \\nabla_x [-\\log p(y,x; w^{-1}, \\sigma_{\\epsilon}^2)] \\big|_{x = 0_K}\\\\\n",
      "p(y; w^{-1}, \\sigma_{\\epsilon}^2) &= (2\\pi)^{K/2} \\, p(y, x_{\\mathrm{MAP}}; w^{-1}, \\sigma_{\\epsilon}^2) \\, |J|^{-1/2}\n",
      "\\end{align}\n",
      "(see http://dx.doi.org/10.1007/s10827-009-0150-x, then do some algebra).\n",
      "\n",
      "Finally, we can estimate the marginal likelihood for the Bernoulli observations by drawing $M$ vectors $w$ whose $K$ elements are sampled from $PG(1,0)$, then\n",
      "$$\n",
      "p(N_{0,K}; \\theta) \\simeq \\frac{1}{M} \\sum_{m=1}^{M} c(w^{(m)},y^{(m)}) \\, p(y^{(m)}; (w^{(m)})^{-1}, \\sigma_{\\epsilon}^2).\n",
      "$$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Do_Kalman_Likelihood(y, sigma2obs, sigma2e):\n",
      "    \"\"\"MAP solution, inverse covariance matrix, and marginal loglikelihood of state-space model\n",
      "\n",
      "    :param y: Observations (K,)\n",
      "    :param sigma2obs: Variance of observation noise (can be scalar or vector)\n",
      "    :param sigma2e: Variance of process noise\n",
      "    :return: x_map, L, marginal_loglikelihood, joint_loglikelihood\n",
      "    \"\"\"\n",
      "    # Build diagonals of information matrix\n",
      "    sigma2obs *= np.ones(len(y))\n",
      "    D = 1. / sigma2obs + 2. / sigma2e\n",
      "    D[-1] = 1. / sigma2obs[-1] + 1. / sigma2e\n",
      "    B = -np.ones(len(D)) / sigma2e\n",
      "    B[-1] = 0.\n",
      "    \n",
      "    # Solve, assuming x_init=0 for simplicity\n",
      "    L = linalg.cholesky_banded((D, B), lower=True)\n",
      "    x_map = linalg.cho_solve_banded([L, True], y / sigma2obs)\n",
      "\n",
      "    # Compute joint and marginal probabilities\n",
      "    joint_loglikelihood = -.5 * ((np.sum(np.diff(x_map)**2) + x_map[0]**2) / sigma2e +\n",
      "                                 np.sum((y - x_map)**2 / sigma2obs) +\n",
      "                                 (len(y) * np.log(2*np.pi*sigma2e * 2*np.pi) + np.sum(np.log(sigma2obs))))\n",
      "    marginal_loglikelihood = len(y)/2. * np.log(2*np.pi) + joint_loglikelihood - np.sum(np.log(L[0]))\n",
      "    return x_map, L, marginal_loglikelihood, joint_loglikelihood"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Marginal_Likelihood_PG(dN, sigma2e, n_samples, ret_accum=False):\n",
      "    K = len(dN)\n",
      "    dN = dN.astype(float)\n",
      "    marginal_loglikelihood_sample = np.zeros(n_samples)\n",
      "    ones, zeros = np.ones(K), np.zeros(K)\n",
      "    for i in range(n_samples):\n",
      "        w = pg.polya_gamma(a=ones, c=zeros)\n",
      "        y = (dN - .5) / w\n",
      "        marginal_loglikelihood_gaus = Do_Kalman_Likelihood(y, 1. / w, sigma2e)[2]\n",
      "        log_c = .5 * (np.sum(w * y**2) - (K * np.log(2/np.pi) + np.sum(np.log(w))))\n",
      "        marginal_loglikelihood_sample[i] = log_c + marginal_loglikelihood_gaus\n",
      "\n",
      "    offset = max(marginal_loglikelihood_sample)\n",
      "    if ret_accum:\n",
      "        accum_marginal_loglikelihood = offset + np.log(np.cumsum(np.exp(marginal_loglikelihood_sample - offset))\n",
      "                                                       / np.arange(1, n_samples+1))\n",
      "        return accum_marginal_loglikelihood\n",
      "    marginal_loglikelihood = offset + np.log(np.mean(np.exp(marginal_loglikelihood_sample - offset)))\n",
      "    return marginal_loglikelihood"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Simple test of Do_Kalman_Likelihood only (K=1, Gaussian)\n",
      "import scipy.stats as stats\n",
      "y = 3.\n",
      "sigma2obs = 10.\n",
      "x_map, L, marginal_loglikelihood, joint_loglikelihood = Do_Kalman_Likelihood(y * np.ones(1), sigma2obs, sigma2e)\n",
      "j = stats.norm.pdf(x_map, 0, np.sqrt(sigma2e)) * stats.norm.pdf(x_map, y, np.sqrt(sigma2obs))\n",
      "m = np.sqrt(2*np.pi) * j / L[0,0]\n",
      "assert(abs(np.log(j) - joint_loglikelihood) < 1e-9)\n",
      "assert(abs(np.log(m) - marginal_loglikelihood) < 1e-9)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Simple test of Marginal_Likelihood_PG (K=1)\n",
      "n_samples = 10000\n",
      "#state = np.random.get_state()\n",
      "#np.random.set_state(state)\n",
      "accum_marginal_loglikelihood = Marginal_Likelihood_PG(np.ones(1), sigma2e, n_samples, ret_accum=True)\n",
      "# normpdf(x,m,s2) := 1/sqrt(2*%pi*s2) * exp(-.5*(x-m)^2/s2);\n",
      "# bernoulli(y, x) := exp(x*y) / (1 + exp(x));\n",
      "# quad_qag(normpdf(x, 0, .5) * bernoulli(1, x), x, -25, 25, 3);\n",
      "#   [0.5000000000000001, 3.188337035858471E-10, 217, 0]\n",
      "# We can actually prove it's 0.5 because = integral( (.5+odd(x)) * gauspdf(x;0,s2e) ) = .5 + 0\n",
      "print(np.log(.5), accum_marginal_loglikelihood[-1])\n",
      "plt.plot(accum_marginal_loglikelihood)\n",
      "plt.plot([0,n_samples-1], [np.log(.5),np.log(.5)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(-0.69314718055994529, -0.6932225117771782)\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "[<matplotlib.lines.Line2D at 0x7f941cbb19d0>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEACAYAAAB78OvLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYmZm2fx/LN2hqn/dj5gAAAAASUVORK5CYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f944846c750>"
       ]
      }
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test Marginal_Likelihood_PG\n",
      "n_samples = 12500\n",
      "%time accum_marginal_loglikelihood = Marginal_Likelihood_PG(dN, sigma2e, n_samples, ret_accum=True)\n",
      "plt.plot(accum_marginal_loglikelihood)\n",
      "print(accum_marginal_loglikelihood[-1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Laplace approximation at the MAP"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Do_Kalman_Likelihood_Bernoulli_LaplaceMAP(dN, sigma2e, tol=1e-8):\n",
      "    \"\"\"MAP solution, inverse covariance matrix, and marginal loglikelihood of state-space model\n",
      "    computed using Laplace approximation around MAP state.\n",
      "\n",
      "    :param dN: Observations (K,)\n",
      "    :param sigma2e: Variance of process noise\n",
      "    :return: x_map, L, marginal_loglikelihood, joint_loglikelihood\n",
      "    \"\"\"\n",
      "    x = np.zeros(dN.shape)\n",
      "    dN = dN.astype(float)\n",
      "    while True:\n",
      "        # Build gradient of joint\n",
      "        d2x = np.convolve(x, [-1, 2, -1])[1:-1]\n",
      "        d2x[-1] -= x[-1]\n",
      "        G = -dN + (1. / (1. + np.exp(-x))) + d2x / sigma2e\n",
      "        # Build Hessian of joint\n",
      "        D = 1. / (np.exp(x) + 2 + np.exp(-x)) + 2. / sigma2e\n",
      "        D[-1] -= 1. / sigma2e\n",
      "        B = -np.ones(len(D)) / sigma2e\n",
      "        B[-1] = 0.\n",
      "        L = linalg.cholesky_banded((D, B), lower=True)\n",
      "        # Check convergence\n",
      "        if np.dot(G, G) < tol:\n",
      "            x_map = x\n",
      "            break\n",
      "        # Update estimate of map\n",
      "        x -= linalg.cho_solve_banded([L, True], G)\n",
      "\n",
      "    # Compute joint and marginal probabilities\n",
      "    joint_loglikelihood = (np.sum(dN * x_map - np.log(1 + np.exp(x_map))) -\n",
      "                           .5 * ((np.sum(np.diff(x_map)**2) + x_map[0]**2) / sigma2e + len(dN) * np.log(2*np.pi*sigma2e)))\n",
      "    marginal_loglikelihood = len(dN)/2. * np.log(2*np.pi) + joint_loglikelihood - np.sum(np.log(L[0]))\n",
      "    return x_map, L, marginal_loglikelihood, joint_loglikelihood"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test Marginal_Likelihood_PG\n",
      "%time x_map_l, L_l, marginal_loglikelihood_l, joint_loglikelihood_l = Do_Kalman_Likelihood_Bernoulli_LaplaceMAP(dN, sigma2e)\n",
      "print(marginal_loglikelihood_l)\n",
      "plt.plot(x_map_l)\n",
      "plt.plot(dN)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s2e = np.arange(.01, 1., .01)\n",
      "marginal_loglikelihood_l = np.zeros_like(s2e)\n",
      "joint_loglikelihood_l = np.zeros_like(s2e)\n",
      "for i in range(len(s2e)):\n",
      "    marginal_loglikelihood_l[i], joint_loglikelihood_l[i] = Do_Kalman_Likelihood_Bernoulli_LaplaceMAP(dN, s2e[i])[2:]\n",
      "plt.plot(s2e, marginal_loglikelihood_l)\n",
      "#plt.plot(s2e, joint_loglikelihood_l)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}